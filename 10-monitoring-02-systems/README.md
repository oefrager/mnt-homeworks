# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?

   К самому минимуму для данного ТЗ можно отнести:
    - CPU     - нагрузка на  процессор, т.к. указали на высокозагруженные вычисления.
    - RAM     - загрузка памяти т.к. нехватка может привести к потере выходных данных 
    - inodes  - загрузка диска, т.к. отчеты используют диск.
    - Net     - время отклика, т.к. взаимодействме происходитт по сети.


#
2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?

    Используем показатель (SLI) для мониторинга и оценкии производительности услуги.
Например:
    - Время отклика, среднее время обработки HTTP-запросов сервером.
    - Доступность сервиса без сбоев в еденицу времени.
    - Уровень ошибок  — доля неудачных запросов по отношению ко всем запросам.
    
     Все это можно закрепить SLA (юридическое соглашение с клиентом).

#
3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

   В этой ситуации подойдет Sentry. Платформа для отслеживания ошибок и мониторинга приложений. 

#
4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

   Не учтены коды ответов 3хх.следует пользоваться формулой:

      (summ_2xx_requests + summ_3xx_requests) / (summ_all_requests)
#
5. Опишите основные плюсы и минусы pull и push систем мониторинга.

pull-модель

```
Плюсы:
   - легче контролировать подлинность данных;
   - можно настроить единый proxy server до всех агентов с TLS;
   - упрощённая отладка получения данных с агентов;

Минусы:
   - Возможны пропуски данных.
   - Увеличенная нагрузка на сервер из-за повторных запросов со стороны множества клиентов.
   - Привязка к определённым инструментам.
```
push-модели
```
Плюсы :
   - Упрощение репликации данных в разные системы мониторинга;
   - более гибкая настройка отправки пакетов данных с метриками;
   - высокая производительность сбора метрик т.к. используется UDP протокол.

Минусы:
   - Меньшая гибкость для потребителей. Не гарантируется порядок доставки сообщений;
   - Возможна перегрузка клиента, если он не может обрабатывать сообщения сразу;
   - Требуется настройка дополнительных механизмов обработки ошибок;
```
   
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus - pull-модель
    - TICK - push-модель
    - Zabbix - Гибридная, push и pull-модель
    - VictoriaMetrics - pull-модель
    - Nagios - pull-модель
#
7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

   ![Снимок экрана от 2025-03-18 18-50-23](https://github.com/user-attachments/assets/9ace9983-e494-4f66-a0a8-d49b02f3bf34)



Для запуска прописал режим `Z` `(..ххх/data:/var/lib.ххх:Z`) и дал права на папки `sudo chmod 777 xxx/data`

#
8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

   ![изображение](https://github.com/user-attachments/assets/8aabbecf-4cee-4816-8713-7437d64deb88)

#
9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

   ![изображение](https://github.com/user-attachments/assets/6040b9de-714b-4fc8-86bd-bce96628237c)

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для запуска мониторинга на python выполняем:
   
   а) код [python3-скрипта](server_sys.py),
   
   б) по cron-расписанию: ``` * * * * *  python /home/goi/server_sys.py```,

получаем выходной сформированный файл: '[YY-MM-DD-awesome-monitoring.log](2025-03-14-awesome-monitoring.log)'.

#
2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---

